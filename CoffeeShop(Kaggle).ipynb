{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp, date_trunc, count\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 1: Load Excel data into a dictionary of DataFrames\n",
    "# ------------------------------------------------------------\n",
    "file = \"/Users/anmolray/Library/CloudStorage/OneDrive-UniversityofWaterloo/InterviewPrep/Coffee Shop Sales:Inventory:Staff/CoffeeShop.xlsx\"\n",
    "xl = pd.ExcelFile(file)\n",
    "d = {}\n",
    "for sheet in xl.sheet_names:\n",
    "    d[sheet] = pd.read_excel(xl, sheet_name=sheet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the orders data from the dictionary\n",
    "\n",
    "if \"orders\" not in d:\n",
    "    raise ValueError(\"The Excel file does not contain a sheet named 'orders'.\")\n",
    "orders_pd = d[\"orders\"]\n",
    "orders_pd = orders_pd.rename(columns={'created_at': 'order_time'}) \n",
    "# Verify that the orders DataFrame has the exact column needed: \"order_time\"\n",
    "if \"order_time\" not in orders_pd.columns:\n",
    "    raise ValueError(\"The 'orders' sheet must contain an 'order_time' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated occupancy data:\n",
      "                  hour  orders_count\n",
      "0  2024-02-12 07:00:00            17\n",
      "1  2024-02-12 08:00:00            16\n",
      "2  2024-02-12 09:00:00            10\n",
      "3  2024-02-12 10:00:00             4\n",
      "4  2024-02-12 11:00:00             3\n",
      "..                 ...           ...\n",
      "61 2024-02-17 13:00:00            11\n",
      "62 2024-02-17 14:00:00             9\n",
      "63 2024-02-17 15:00:00             5\n",
      "64 2024-02-17 16:00:00             4\n",
      "65 2024-02-17 17:00:00             1\n",
      "\n",
      "[66 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Spark DataFrame and aggregate orders by hour\n",
    "\n",
    "spark = SparkSession.builder.appName(\"OccupancyForecasting\").getOrCreate()\n",
    "\n",
    "# Create Spark DataFrame from the orders pandas DataFrame\n",
    "orders_df = spark.createDataFrame(orders_pd)\n",
    "\n",
    "# Convert the order_time column to a timestamp (using the exact column name)\n",
    "orders_df = orders_df.withColumn(\"order_time\", to_timestamp(\"order_time\"))\n",
    "\n",
    "# Aggregate by hour: count orders per hour as a proxy for occupancy\n",
    "hourly_orders = (orders_df\n",
    "                 .groupBy(date_trunc(\"hour\", orders_df.order_time).alias(\"hour\"))\n",
    "                 .agg(count(\"*\").alias(\"orders_count\"))\n",
    "                 .orderBy(\"hour\"))\n",
    "\n",
    "# Convert the aggregated Spark DataFrame to a pandas DataFrame for further processing\n",
    "data = hourly_orders.toPandas()\n",
    "data['hour'] = pd.to_datetime(data['hour'])\n",
    "data = data.sort_values(\"hour\")\n",
    "print(\"Aggregated occupancy data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for Time Series\n",
    "# Use the exact \"orders_count\" column produced by our aggregation as our time series\n",
    "occupancy_series = data['orders_count'].values.astype(float)\n",
    "\n",
    "# Normalize the time series\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "occupancy_scaled = scaler.fit_transform(occupancy_series.reshape(-1, 1))\n",
    "\n",
    "def create_dataset(dataset, seq_length):\n",
    "    \"\"\"\n",
    "    Creates input/output pairs for time series forecasting.\n",
    "    Each input sequence consists of 'seq_length' consecutive time steps\n",
    "    and the corresponding target is the immediate next value.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - seq_length):\n",
    "        X.append(dataset[i:i+seq_length])\n",
    "        y.append(dataset[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Use the past 2 hours to predict the next hour\n",
    "seq_length = 2  \n",
    "X, y = create_dataset(occupancy_scaled, seq_length)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (num_samples, seq_length)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)  # Shape: (num_samples, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PyTorch LSTM forecasting model\n",
    "\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, output_size=1):\n",
    "        super(LSTMForecast, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Forward propagate LSTM; x shape should be (batch_size, seq_length, input_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # Use the output of the last time step for forecasting\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = LSTMForecast()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.0447\n",
      "Epoch [20/1000], Loss: 0.0447\n",
      "Epoch [30/1000], Loss: 0.0447\n",
      "Epoch [40/1000], Loss: 0.0447\n",
      "Epoch [50/1000], Loss: 0.0447\n",
      "Epoch [60/1000], Loss: 0.0447\n",
      "Epoch [70/1000], Loss: 0.0447\n",
      "Epoch [80/1000], Loss: 0.0447\n",
      "Epoch [90/1000], Loss: 0.0447\n",
      "Epoch [100/1000], Loss: 0.0447\n",
      "Epoch [110/1000], Loss: 0.0447\n",
      "Epoch [120/1000], Loss: 0.0447\n",
      "Epoch [130/1000], Loss: 0.0447\n",
      "Epoch [140/1000], Loss: 0.0447\n",
      "Epoch [150/1000], Loss: 0.0447\n",
      "Epoch [160/1000], Loss: 0.0447\n",
      "Epoch [170/1000], Loss: 0.0447\n",
      "Epoch [180/1000], Loss: 0.0447\n",
      "Epoch [190/1000], Loss: 0.0447\n",
      "Epoch [200/1000], Loss: 0.0447\n",
      "Epoch [210/1000], Loss: 0.0447\n",
      "Epoch [220/1000], Loss: 0.0447\n",
      "Epoch [230/1000], Loss: 0.0447\n",
      "Epoch [240/1000], Loss: 0.0447\n",
      "Epoch [250/1000], Loss: 0.0447\n",
      "Epoch [260/1000], Loss: 0.0447\n",
      "Epoch [270/1000], Loss: 0.0447\n",
      "Epoch [280/1000], Loss: 0.0447\n",
      "Epoch [290/1000], Loss: 0.0447\n",
      "Epoch [300/1000], Loss: 0.0447\n",
      "Epoch [310/1000], Loss: 0.0447\n",
      "Epoch [320/1000], Loss: 0.0447\n",
      "Epoch [330/1000], Loss: 0.0447\n",
      "Epoch [340/1000], Loss: 0.0447\n",
      "Epoch [350/1000], Loss: 0.0447\n",
      "Epoch [360/1000], Loss: 0.0447\n",
      "Epoch [370/1000], Loss: 0.0447\n",
      "Epoch [380/1000], Loss: 0.0447\n",
      "Epoch [390/1000], Loss: 0.0447\n",
      "Epoch [400/1000], Loss: 0.0447\n",
      "Epoch [410/1000], Loss: 0.0447\n",
      "Epoch [420/1000], Loss: 0.0447\n",
      "Epoch [430/1000], Loss: 0.0447\n",
      "Epoch [440/1000], Loss: 0.0447\n",
      "Epoch [450/1000], Loss: 0.0447\n",
      "Epoch [460/1000], Loss: 0.0447\n",
      "Epoch [470/1000], Loss: 0.0447\n",
      "Epoch [480/1000], Loss: 0.0447\n",
      "Epoch [490/1000], Loss: 0.0447\n",
      "Epoch [500/1000], Loss: 0.0447\n",
      "Epoch [510/1000], Loss: 0.0447\n",
      "Epoch [520/1000], Loss: 0.0447\n",
      "Epoch [530/1000], Loss: 0.0447\n",
      "Epoch [540/1000], Loss: 0.0447\n",
      "Epoch [550/1000], Loss: 0.0447\n",
      "Epoch [560/1000], Loss: 0.0447\n",
      "Epoch [570/1000], Loss: 0.0447\n",
      "Epoch [580/1000], Loss: 0.0447\n",
      "Epoch [590/1000], Loss: 0.0447\n",
      "Epoch [600/1000], Loss: 0.0447\n",
      "Epoch [610/1000], Loss: 0.0447\n",
      "Epoch [620/1000], Loss: 0.0447\n",
      "Epoch [630/1000], Loss: 0.0447\n",
      "Epoch [640/1000], Loss: 0.0447\n",
      "Epoch [650/1000], Loss: 0.0447\n",
      "Epoch [660/1000], Loss: 0.0447\n",
      "Epoch [670/1000], Loss: 0.0447\n",
      "Epoch [680/1000], Loss: 0.0447\n",
      "Epoch [690/1000], Loss: 0.0447\n",
      "Epoch [700/1000], Loss: 0.0447\n",
      "Epoch [710/1000], Loss: 0.0447\n",
      "Epoch [720/1000], Loss: 0.0447\n",
      "Epoch [730/1000], Loss: 0.0447\n",
      "Epoch [740/1000], Loss: 0.0447\n",
      "Epoch [750/1000], Loss: 0.0447\n",
      "Epoch [760/1000], Loss: 0.0447\n",
      "Epoch [770/1000], Loss: 0.0447\n",
      "Epoch [780/1000], Loss: 0.0447\n",
      "Epoch [790/1000], Loss: 0.0447\n",
      "Epoch [800/1000], Loss: 0.0447\n",
      "Epoch [810/1000], Loss: 0.0447\n",
      "Epoch [820/1000], Loss: 0.0447\n",
      "Epoch [830/1000], Loss: 0.0447\n",
      "Epoch [840/1000], Loss: 0.0447\n",
      "Epoch [850/1000], Loss: 0.0447\n",
      "Epoch [860/1000], Loss: 0.0447\n",
      "Epoch [870/1000], Loss: 0.0447\n",
      "Epoch [880/1000], Loss: 0.0447\n",
      "Epoch [890/1000], Loss: 0.0447\n",
      "Epoch [900/1000], Loss: 0.0447\n",
      "Epoch [910/1000], Loss: 0.0447\n",
      "Epoch [920/1000], Loss: 0.0447\n",
      "Epoch [930/1000], Loss: 0.0447\n",
      "Epoch [940/1000], Loss: 0.0447\n",
      "Epoch [950/1000], Loss: 0.0447\n",
      "Epoch [960/1000], Loss: 0.0447\n",
      "Epoch [970/1000], Loss: 0.0447\n",
      "Epoch [980/1000], Loss: 0.0447\n",
      "Epoch [990/1000], Loss: 0.0447\n",
      "Epoch [1000/1000], Loss: 0.0447\n"
     ]
    }
   ],
   "source": [
    "#  Train LSTM model\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 1000  # Adjust the number of epochs as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Ensure input tensor has shape: (batch_size, seq_length, input_size)\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted occupancy for next hour: 7.626443\n"
     ]
    }
   ],
   "source": [
    "#  Forecast the next hour's customer occupancy\n",
    "\n",
    "model.eval()\n",
    "# Prepare the last sequence from the scaled data for prediction\n",
    "last_seq = torch.tensor(occupancy_scaled[-seq_length:], dtype=torch.float32).unsqueeze(0)\n",
    "predicted = model(last_seq).detach().numpy()\n",
    "# Convert the prediction back to the original scale\n",
    "predicted_occupancy = scaler.inverse_transform(predicted)\n",
    "print(\"\\nPredicted occupancy for next hour:\", predicted_occupancy[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized staff count for next hour: 2\n"
     ]
    }
   ],
   "source": [
    "#optimize staffing based on the prediction\n",
    "\n",
    "# Using a simple rule: one staff per 5 customers, with a minimum of 2 staff members.\n",
    "predicted_customers = predicted_occupancy[0][0]\n",
    "staff_needed = max(2, int(np.ceil(predicted_customers / 5)))\n",
    "print(\"Optimized staff count for next hour:\", staff_needed)\n",
    "\n",
    "# Stop the Spark session when done\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
